#!/usr/bin/env python3
"""
üéØ TRANSCRIPT ANALYZER - CLI PRINCIPAL
üîß python run_analysis.py --project grupo_docentes

Interface de linha de comando para an√°lise automatizada de entrevistas.
"""

import argparse
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Optional, List

# Importar m√≥dulos do sistema
try:
    from config_loader import ConfigLoader, ResourceManager, ProjectConfig
    from engine.analyzer_core import TranscriptAnalyzer
    from visuals.dashboard_generator import DashboardGenerator
except ImportError as e:
    print(f"‚ùå Erro ao importar m√≥dulos b√°sicos: {e}")
    print("üí° Execute primeiro: python setup.py para configurar o ambiente")
    sys.exit(1)

# Tentar importar sistema escal√°vel de visualiza√ß√µes
try:
    from visuals.visualization_manager import ScalableVisualizationManager
    SCALABLE_VISUALS = True
    print("‚úÖ Sistema escal√°vel de visualiza√ß√µes carregado")
except ImportError:
    SCALABLE_VISUALS = False
    print("‚ö†Ô∏è Sistema escal√°vel n√£o dispon√≠vel, usando sistema tradicional")


class AnalysisRunner:
    """üöÄ Orquestrador principal das an√°lises"""
    
    def __init__(self):
        self.config_loader = ConfigLoader()
        self.resource_manager = ResourceManager(self.config_loader)
        
    def run_single_analysis(self, project_name: str, file_path: Optional[str] = None):
        """üìä Executa an√°lise individual"""
        
        print(f"üéØ INICIANDO AN√ÅLISE: {project_name}")
        print("=" * 50)
        
        try:
            # 1. Carregar configura√ß√£o
            config = self.config_loader.load_project_config(project_name)
            print(f"‚úÖ Configura√ß√£o carregada: {config.project_name}")
            
            # 2. Inicializar analisador
            analyzer = TranscriptAnalyzer(config, self.resource_manager)
            
            # 3. Detectar arquivos para an√°lise
            project_dir = self.config_loader.projects_dir / project_name
            if file_path:
                files_to_analyze = [Path(file_path)]
            else:
                files_to_analyze = list((project_dir / "arquivos").glob("*.txt"))
            
            if not files_to_analyze:
                print("‚ùå Nenhum arquivo .txt encontrado em arquivos/")
                return False
            
            print(f"üìÅ Arquivos detectados: {len(files_to_analyze)}")
            
            # 4. Processar cada arquivo
            results = []
            for file_path in files_to_analyze:
                print(f"\nüîç Analisando: {file_path.name}")
                
                try:
                    result = analyzer.analyze_transcript(file_path)

                    # DEBUG - Verificar dados dispon√≠veis
                    print("\nüîç DEBUG - Dados completos dispon√≠veis:")
                    print(f"  ‚úì temporal_analysis: {len(result.get('temporal_analysis', []))} pontos")
                    print(f"  ‚úì word_frequencies: {len(result.get('word_frequencies', {}))} palavras")
                    print(f"  ‚úì linguistic_patterns: {'‚úì' if result.get('linguistic_patterns') else '‚úó'}")
                    print(f"  ‚úì topic_hierarchy: {len(result.get('topic_hierarchy', {}).get('nodes', []))} n√≥s")
                    print(f"  ‚úì phases: {len(result.get('phases', {}))} fases")
                    print(f"  ‚úì contradictions: {len(result.get('contradictions', []))} contradi√ß√µes")
                    print("="*60)

                    result['filename'] = file_path.name
                    results.append(result)
                    print(f"‚úÖ {file_path.name} processado")
                    
                except Exception as e:
                    print(f"‚ùå Erro em {file_path.name}: {e}")
                    continue
            
            if not results:
                print("‚ùå Nenhuma an√°lise foi conclu√≠da com sucesso")
                return False
            
            # 5. Gerar visualiza√ß√µes
            if config.output['generate_visuals']:
                print(f"\nüìä Gerando visualiza√ß√µes...")
                
                for result in results:
                    output_dir = project_dir / "output" / result['filename'].replace('.txt', '')
                    output_dir.mkdir(parents=True, exist_ok=True)
                    # Criar subpasta para assets
                    assets_dir = output_dir / "assets"
                    assets_dir.mkdir(parents=True, exist_ok=True)
                    
                    # Usar m√©todo inteligente de visualiza√ß√£o
                    self._generate_visualizations_smart(result, str(output_dir), config)
            
            # 6. Gerar relat√≥rios se habilitado
            if config.output['generate_markdown']:
                print(f"\nüìù Gerando relat√≥rios...")
                self._generate_markdown_reports(results, project_dir / "output")
            
            # 7. Resumo final
            self._print_analysis_summary(results, project_name)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erro cr√≠tico na an√°lise: {e}")
            return False
    
    def _generate_visualizations_smart(self, result, output_dir, config):
        """üé® Gera visualiza√ß√µes usando sistema escal√°vel ou fallback"""
        
        if SCALABLE_VISUALS:
            try:
                # Usar sistema novo e escal√°vel
                viz_manager = ScalableVisualizationManager(config.output)
                
                print(f"üé® Backends dispon√≠veis: {viz_manager.get_available_backends()}")
                
                # Gr√°fico de m√©tricas
                metrics_data = {
                    'categories': ['Sentimento', 'Coer√™ncia', 'Abertura'],
                    'values': [
                        result['global_metrics']['global_sentiment'],
                        result['global_metrics']['thematic_coherence'], 
                        result['global_metrics']['emotional_openness']
                    ]
                }
                extension = 'html' if hasattr(viz_manager, 'primary_backend') and viz_manager.primary_backend == 'plotly' else 'png'

                metrics_config = {
                    'title': f'M√©tricas Globais - {result["filename"]}',
                    'output_path': str(Path(output_dir) / f'metricas_globais.{extension}'),
                    'figsize': (12, 8),
                    'bar_params': {'alpha': 0.8, 'color': ['skyblue', 'lightgreen', 'coral']}
                }
                
                viz_manager.create_visualization('bar_chart', metrics_data, metrics_config)
                
                # DEBUG tempor√°rio
                print(f"\nüîç DEBUG - Dados dispon√≠veis para {result['filename']}:")
                print(f"  - temporal_analysis: {len(result.get('temporal_analysis', []))} items")
                print(f"  - concept_network: {len(result.get('concept_network', []))} items")
                if result.get('concept_network'):
                    print(f"  - Primeiro item network: {result['concept_network'][0]}")
                
                # Timeline emocional se houver dados temporais
                if result.get('temporal_analysis'):
                    timeline_data = {
                        'x': [i for i in range(len(result['temporal_analysis']))],
                        'y': [seg['sentiment'] for seg in result['temporal_analysis']]
                    }
                    
                    timeline_config = {
                        'title': 'Timeline Emocional',
                        'xlabel': 'Segmentos',
                        'ylabel': 'Sentimento',
                        'output_path': str(Path(output_dir) / 'timeline_emocional.html'),
                        'trace_name': 'Evolu√ß√£o Emocional'
                    }
                    
                    viz_manager.create_visualization('line_plot', timeline_data, timeline_config, backend='plotly')
                
                # Rede de conceitos se dispon√≠vel
                if result.get('concept_network'):
                    network_data = {
                        'nodes': [conn['word1'] for conn in result['concept_network'][:10]] + 
                                [conn['word2'] for conn in result['concept_network'][:10]],
                        'edges': [(conn['word1'], conn['word2']) for conn in result['concept_network'][:10]]
                    }
                    
                    network_config = {
                        'title': 'Rede de Conceitos',
                        'output_path': str(Path(output_dir) / 'rede_conceitos.html'),
                        'node_params': {'node_size': 300, 'node_color': 'lightblue'},
                        'edge_params': {'width': 2, 'alpha': 0.7}
                    }
                    
                    viz_manager.create_visualization('network_graph', network_data, network_config, backend='plotly')
                # 4. Word Cloud (usando bar chart por enquanto)
                if result.get('word_frequencies'):
                    # Pegar top 10 palavras mais frequentes
                    sorted_words = sorted(result['word_frequencies'].items(), 
                                        key=lambda x: x[1], 
                                        reverse=True)[:10]
                    
                    wordcloud_data = {
                        'words': [word for word, freq in sorted_words],      # Mudou de 'categories' para 'words'
                        'frequencies': [freq for word, freq in sorted_words]  # Mudou de 'values' para 'frequencies'
                    }
                    
                    wordcloud_config = {
                        'title': f'Word Cloud - {result["filename"]}',
                        'output_path': str(Path(output_dir) / 'wordcloud.html'),
                        'xlabel': 'Palavras',
                        'ylabel': 'Frequ√™ncia',
                        'figsize': (12, 6),
                        'bar_params': {'alpha': 0.9, 'color': 'purple'}
                    }
                    # DEBUG wordcloud
                    print(f"DEBUG Wordcloud - Top 5 palavras: {list(result['word_frequencies'].items())[:5]}")
                    #viz_manager.create_visualization('wordcloud', wordcloud_data, wordcloud_config)

                    # DEBUG para wordcloud
                    print(f"DEBUG - Tipo de visualiza√ß√£o: wordcloud")
                    print(f"DEBUG - Backends dispon√≠veis: {viz_manager.get_available_backends()}")
                    print(f"DEBUG - Backend prim√°rio: {viz_manager.primary_backend}")

                    # DEBUG - Verificar se o m√©todo existe
                    print(f"DEBUG - PlotlyBackend tem create_wordcloud? {hasattr(viz_manager.backends.get('plotly'), 'create_wordcloud')}")
                    print(f"DEBUG - M√©todos dispon√≠veis no PlotlyBackend: {[m for m in dir(viz_manager.backends.get('plotly')) if m.startswith('create_')]}")

                    # For√ßar uso direto do m√©todo wordcloud
                    if hasattr(viz_manager.backends.get('plotly'), 'create_wordcloud'):
                        output = viz_manager.backends['plotly'].create_wordcloud(wordcloud_data, wordcloud_config)
                        print(f"‚úÖ Word Cloud criado diretamente: {output}")
                    else:
                        viz_manager.create_visualization('wordcloud', wordcloud_data, wordcloud_config)
                
                # 4.1 Top 10 Palavras em Barras (complementar ao wordcloud)
                if result.get('word_frequencies'):
                    # Mesmos dados, mas para gr√°fico de barras
                    sorted_words = sorted(result['word_frequencies'].items(), 
                                        key=lambda x: x[1], 
                                        reverse=True)[:10]
                    
                    bar_words_data = {
                        'categories': [word for word, freq in sorted_words],
                        'values': [freq for word, freq in sorted_words]
                    }
                    
                    bar_words_config = {
                        'title': f'Top 10 Palavras (Frequ√™ncia) - {result["filename"]}',
                        'output_path': str(Path(output_dir) / 'top_palavras_freq.html'),
                        'xlabel': 'Palavras',
                        'ylabel': 'Frequ√™ncia',
                        'figsize': (12, 6),
                        'bar_params': {'alpha': 0.9, 'color': 'indigo'}
                    }
                    
                    viz_manager.create_visualization('bar_chart', bar_words_data, bar_words_config)

                # 5. Padr√µes Lingu√≠sticos
                if result.get('linguistic_patterns'):
                    patterns = result['linguistic_patterns']
                    patterns_data = {
                        'categories': ['Certeza', 'Incerteza', 'Hesita√ß√µes'],
                        'values': [
                            patterns.get('certainty_markers', {}).get('count', 0),
                            patterns.get('uncertainty_markers', {}).get('count', 0),
                            patterns.get('total_hesitations', 0)
                        ]
                    }
                    
                    patterns_config = {
                        'title': f'Padr√µes Lingu√≠sticos - {result["filename"]}',
                        'output_path': str(Path(output_dir) / 'padroes_linguisticos.html'),
                        'figsize': (10, 6),
                        'bar_params': {'alpha': 0.8, 'color': ['green', 'orange', 'red']}
                    }
                    
                    viz_manager.create_visualization('bar_chart', patterns_data, patterns_config)

                # 6. Hierarquia de T√≥picos
                if result.get('topic_hierarchy') and result['topic_hierarchy'].get('nodes'):
                    # Agora sabemos que nodes tem 'id' e 'label'
                    hierarchy_data = {
                        'nodes': [node['label'] for node in result['topic_hierarchy']['nodes'][:15]],
                        'edges': [(edge['source'], edge['target']) for edge in result['topic_hierarchy'].get('edges', [])]
                    }
                    
                    hierarchy_config = {
                        'title': f'Hierarquia de T√≥picos - {result["filename"]}',
                        'output_path': str(Path(output_dir) / 'hierarquia_topicos.html'),
                        'node_params': {'node_size': 500, 'node_color': 'lightcoral'},
                        'edge_params': {'width': 1, 'alpha': 0.5}
                    }
                    
                    viz_manager.create_visualization('network_graph', hierarchy_data, hierarchy_config)
                
                # 7. An√°lise de Contradi√ß√µes
                if result.get('contradictions') and len(result['contradictions']) > 0:
                    contradictions_data = {
                        'categories': [f"Contradi√ß√£o {i+1}" for i in range(len(result['contradictions']))],
                        'values': [c['score'] for c in result['contradictions']]
                    }
                    
                    contradictions_config = {
                        'title': f'An√°lise de Contradi√ß√µes - {result["filename"]}',
                        'output_path': str(Path(output_dir) / 'contradicoes.html'),
                        'xlabel': 'Contradi√ß√µes Detectadas',
                        'ylabel': 'Score de Contradi√ß√£o',
                        'figsize': (10, 6),
                        'bar_params': {'alpha': 0.7, 'color': 'salmon'}
                    }
                    
                    viz_manager.create_visualization('bar_chart', contradictions_data, contradictions_config)

                

                print("‚úÖ Visualiza√ß√µes escal√°veis geradas")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro no sistema escal√°vel: {e}")
                print("üîÑ Usando sistema tradicional como fallback...")
                self._generate_visualizations_traditional(result, output_dir, config)
        else:
            # Usar sistema tradicional
            self._generate_visualizations_traditional(result, output_dir, config)
    
    def _generate_visualizations_traditional(self, result, output_dir, config):
        """üìä Gera visualiza√ß√µes usando sistema tradicional"""
        try:
            dashboard = DashboardGenerator(config)
            dashboard.generate_complete_dashboard(result, output_dir)
            print("‚úÖ Visualiza√ß√µes tradicionais geradas")
        except Exception as e:
            print(f"‚ùå Erro ao gerar visualiza√ß√µes tradicionais: {e}")
    
    def run_comparative_analysis(self, project_names: List[str]):
        """üîÑ Executa an√°lise comparativa entre projetos"""
        
        print(f"üîÑ AN√ÅLISE COMPARATIVA")
        print(f"üìä Projetos: {', '.join(project_names)}")
        print("=" * 50)
        
        try:
            all_results = []
            
            # Coletar resultados de todos os projetos
            for project_name in project_names:
                config = self.config_loader.load_project_config(project_name)
                analyzer = TranscriptAnalyzer(config, self.resource_manager)
                
                project_dir = self.config_loader.projects_dir / project_name
                files = list((project_dir / "arquivos").glob("*.txt"))
                
                project_results = []
                for file_path in files:
                    result = analyzer.analyze_transcript(file_path)
                    result['project'] = project_name
                    result['filename'] = file_path.name
                    project_results.append(result)
                
                all_results.extend(project_results)
                print(f"‚úÖ {project_name}: {len(project_results)} arquivos processados")
            
            # An√°lise comparativa
            from engine.comparative_analyzer import ComparativeAnalyzer
            
            comp_analyzer = ComparativeAnalyzer()
            comparison_results = comp_analyzer.compare_projects(all_results)
            
            # Gerar visualiza√ß√µes comparativas
            dashboard = DashboardGenerator(None)  # Usar config padr√£o para compara√ß√£o
            
            # Criar apenas a pasta comparisons se n√£o existir
            comparisons_dir = Path("projects/comparisons")
            comparisons_dir.mkdir(parents=True, exist_ok=True)

            # Gerar nome √∫nico para a imagem
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"comparative_{timestamp}_test.png"
            output_path = comparisons_dir / output_filename
            
            dashboard.generate_comparative_dashboard(
                comparison_results,
                output_dir=str(comparisons_dir),
                output_path=str(output_path)
            )
            
            print(f"\n‚úÖ An√°lise comparativa conclu√≠da")
            print(f"üìÇ Resultados salvos em: {output_path}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise comparativa: {e}")
            return False
    
    def _generate_markdown_reports(self, results: List[dict], output_dir: Path):
        """üìù Gera relat√≥rios em Markdown"""
        
        for result in results:
            # Criar caminho correto dentro da pasta do arquivo
            file_folder = result['filename'].replace('.txt', '')
            # output_dir j√° √© projects/nome/output/
            # Ent√£o: projects/nome/output/arquivo/arquivo.md
            report_path = output_dir / file_folder / f"_report_{file_folder}.md"
            
            # Garantir que a pasta existe (caso ainda n√£o tenha sido criada)
            report_path.parent.mkdir(parents=True, exist_ok=True)
            
            try:
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write(self._create_markdown_content(result))
                
                print(f"üìÑ Relat√≥rio gerado: {file_folder}.md")
            except Exception as e:
                print(f"‚ùå Erro ao gerar relat√≥rio {file_folder}.md: {e}")
    
    def _create_markdown_content(self, result: dict) -> str:
        """üìã Cria conte√∫do do relat√≥rio em Markdown"""
        
        content = f"""# An√°lise de Entrevista: {result['filename']}

**Data da An√°lise:** {datetime.now().strftime('%d/%m/%Y %H:%M')}

## üìä M√©tricas Globais

- **Sentimento Global:** {result['global_metrics']['global_sentiment']:.2f}
- **Coer√™ncia Tem√°tica:** {result['global_metrics']['thematic_coherence']:.2f}
- **Abertura Emocional:** {result['global_metrics']['emotional_openness']:.2f}

"""
        
        # Evolu√ß√£o Temporal
        if result.get('temporal_analysis'):
            content += "## üìà Evolu√ß√£o Temporal\n\n"
            phases = result.get('phases', {})
            for phase_name, phase_data in phases.items():
                if phase_data.get('sentiment_avg') is not None:
                    sentiment_emoji = "üòä" if phase_data['sentiment_avg'] > 0 else "üòê" if phase_data['sentiment_avg'] == 0 else "üòî"
                    content += f"- **{phase_name}**: {sentiment_emoji} Sentimento m√©dio: {phase_data['sentiment_avg']:.2f}\n"
            content += "\n"
        
        # Top 10 Palavras
        if result.get('word_frequencies'):
            content += "## üî§ Top 10 Palavras Mais Frequentes\n\n"
            for i, (word, freq) in enumerate(list(result['word_frequencies'].items())[:10], 1):
                content += f"{i}. **{word}**: {freq} vezes\n"
            content += "\n"
        
        # T√≥picos Principais
        content += "## üìà T√≥picos Principais\n\n"
        for i, topic in enumerate(result['topics'][:5]):
            distribution = result['topic_distribution'][i]
            content += f"### T√≥pico {i+1} ({distribution:.1%})\n"
            content += f"**Palavras-chave:** {', '.join(topic['words'][:8])}\n\n"
        
        # Rede de Conceitos
        if result.get('concept_network'):
            content += "## üï∏Ô∏è Principais Conex√µes entre Conceitos\n\n"
            for conn in result['concept_network'][:10]:
                content += f"- {conn['word1']} ‚Üî {conn['word2']} (for√ßa: {conn['weight']})\n"
            content += "\n"
        
        # An√°lise Lingu√≠stica
        content += "## üé≠ An√°lise Lingu√≠stica\n"
        
        linguistic = result.get('linguistic_patterns', {})
        
        # Para compatibilidade com estrutura antiga E nova
        if 'uncertainty_markers' in linguistic:
            uncertainty = linguistic.get('uncertainty_markers', {}).get('count', 0)
            certainty = linguistic.get('certainty_markers', {}).get('count', 0)
        else:
            uncertainty = linguistic.get('uncertainty_count', 0)
            certainty = linguistic.get('certainty_count', 0)
        
        content += f"- **Total de Hesita√ß√µes:** {linguistic.get('total_hesitations', 0)}\n"
        content += f"- **Marcadores de Incerteza:** {uncertainty}\n"
        content += f"- **Marcadores de Certeza:** {certainty}\n"
        
        if certainty > 0:
            ratio = uncertainty / certainty
            content += f"- **Raz√£o Incerteza/Certeza:** {ratio:.2f}\n"
        else:
            content += f"- **Raz√£o Incerteza/Certeza:** N/A\n"
            
        content += f"- **Complexidade M√©dia:** {linguistic.get('avg_sentence_length', 0):.1f} palavras/frase\n\n"
        
        # Padr√µes de Hesita√ß√£o
        if linguistic.get('hesitation_phrases'):
            content += "## üí¨ Padr√µes de Hesita√ß√£o\n\n"
            for word, count in sorted(linguistic['hesitation_phrases'].items(), key=lambda x: x[1], reverse=True)[:5]:
                content += f"- **{word}**: {count} ocorr√™ncias\n"
            content += "\n"
        
        # Contradi√ß√µes (se existirem)
        if result.get('contradictions'):
            content += "## ‚ö†Ô∏è Contradi√ß√µes Detectadas\n\n"
            for i, contradiction in enumerate(result['contradictions'][:3]):
                content += f"### Contradi√ß√£o {i+1}\n"
                if 'topic_words' in contradiction:
                    content += f"- **T√≥pico:** {', '.join(contradiction['topic_words'][:5])}\n"
                elif 'text1' in contradiction:
                    content += f"- **Texto 1:** \"{contradiction.get('text1', '')[:50]}...\"\n"
                    content += f"- **Texto 2:** \"{contradiction.get('text2', '')[:50]}...\"\n"

                if 'intensity' in contradiction:
                    content += f"- **Intensidade:** {contradiction['intensity']:.2f}\n\n"
                elif 'score' in contradiction:
                    content += f"- **Score:** {contradiction['score']:.2f}\n\n"
                else:
                    content += "\n"
        
        return content
    
    def _print_analysis_summary(self, results: List[dict], project_name: str):
        """üìã Imprime resumo da an√°lise"""
        
        print(f"\nüéØ RESUMO DA AN√ÅLISE: {project_name}")
        print("=" * 50)
        
        print(f"üìÅ Arquivos processados: {len(results)}")
        
        # M√©tricas m√©dias
        avg_sentiment = sum(r['global_metrics']['global_sentiment'] for r in results) / len(results)
        avg_coherence = sum(r['global_metrics']['thematic_coherence'] for r in results) / len(results)
        avg_openness = sum(r['global_metrics']['emotional_openness'] for r in results) / len(results)
        
        print(f"üòä Sentimento m√©dio: {avg_sentiment:+.2f}")
        print(f"üéØ Coer√™ncia m√©dia: {avg_coherence:.2f}")
        print(f"üí≠ Abertura m√©dia: {avg_openness:.2f}")
        
        # Arquivos com problemas
        problematic = [r for r in results if r['global_metrics']['thematic_coherence'] < 0.3]
        if problematic:
            print(f"\n‚ö†Ô∏è Arquivos com baixa coer√™ncia: {len(problematic)}")
            for r in problematic:
                print(f"   - {r['filename']}")
        
        print(f"\n‚úÖ An√°lise conclu√≠da com sucesso!")


def test_visualization_system():
    """üß™ Testa o sistema de visualiza√ß√µes"""
    
    print("üß™ TESTANDO SISTEMA DE VISUALIZA√á√ïES")
    print("=" * 50)
    
    if not SCALABLE_VISUALS:
        print("‚ùå Sistema escal√°vel n√£o dispon√≠vel para teste")
        return
    
    try:
        from visuals.visualization_manager import ScalableVisualizationManager
        
        # Criar gerenciador
        viz_manager = ScalableVisualizationManager()
        
        print(f"üé® Backends dispon√≠veis: {viz_manager.get_available_backends()}")
        
        # Dados de teste
        test_data = {
            'categories': ['A', 'B', 'C', 'D'],
            'values': [10, 25, 15, 30]
        }
        
        test_config = {
            'title': 'Teste de Gr√°fico de Barras',
            'output_path': 'test_bar_chart.png',
            'xlabel': 'Categorias',
            'ylabel': 'Valores'
        }
        
        # Testar cada backend
        for backend in viz_manager.get_available_backends():
            print(f"\nüîß Testando backend: {backend}")
            
            test_config['output_path'] = f'test_bar_chart_{backend}.png'
            if backend == 'plotly':
                test_config['output_path'] = f'test_bar_chart_{backend}.html'
            
            result = viz_manager.create_visualization('bar_chart', test_data, test_config, backend)
            
            if result:
                print(f"‚úÖ Sucesso: {result}")
            else:
                print(f"‚ùå Falha no backend {backend}")
        
        print("\n‚úÖ Teste conclu√≠do!")
        
    except Exception as e:
        print(f"‚ùå Erro no teste: {e}")


def main():
    """üéØ Fun√ß√£o principal do CLI"""
    
    parser = argparse.ArgumentParser(
        description="üéØ Transcript Analyzer - An√°lise automatizada de entrevistas qualitativas",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python run_analysis.py --project grupo_docentes
  python run_analysis.py --project professores_2024 --file entrevista1.txt
  python run_analysis.py --compare projeto1 projeto2 projeto3
  python run_analysis.py --test-visuals
        """
    )
    
    parser.add_argument(
        '--project', '-p',
        help="Nome do projeto para an√°lise"
    )
    
    parser.add_argument(
        '--file', '-f',
        help="Arquivo espec√≠fico para analisar (opcional)"
    )
    
    parser.add_argument(
        '--compare', '-c',
        nargs='+',
        help="Executar an√°lise comparativa entre projetos"
    )
    
    parser.add_argument(
        '--create-project',
        help="Criar novo projeto com estrutura padr√£o"
    )
    
    parser.add_argument(
        '--list-projects', '-l',
        action='store_true',
        help="Listar projetos dispon√≠veis"
    )
    
    parser.add_argument(
        '--setup',
        action='store_true',
        help="Configurar ambiente inicial"
    )
    
    parser.add_argument(
        '--test-visuals',
        action='store_true',
        help="Testar sistema de visualiza√ß√µes"
    )
    
    args = parser.parse_args()
    
    # Configurar ambiente se solicitado
    if args.setup:
        from config_loader import setup_environment
        setup_environment()
        return
    
    # Testar visualiza√ß√µes
    if args.test_visuals:
        test_visualization_system()
        return
    
    runner = AnalysisRunner()
    
    # Criar projeto
    if args.create_project:
        runner.config_loader.create_default_project(args.create_project)
        print(f"‚úÖ Projeto '{args.create_project}' criado")
        print(f"üìÅ Adicione arquivos .txt em: projects/{args.create_project}/arquivos/")
        return
    
    # Listar projetos
    if args.list_projects:
        projects_dir = runner.config_loader.projects_dir
        projects = [d.name for d in projects_dir.iterdir() if d.is_dir()]
        
        if projects:
            print("üìÅ Projetos dispon√≠veis:")
            for project in projects:
                config_file = projects_dir / project / "config_analise.json"
                status = "‚úÖ" if config_file.exists() else "‚ùå"
                print(f"   {status} {project}")
        else:
            print("‚ùå Nenhum projeto encontrado")
            print("üí° Use: --create-project nome_projeto")
        return
    
    # An√°lise comparativa
    if args.compare:
        success = runner.run_comparative_analysis(args.compare)
        sys.exit(0 if success else 1)
    
    # An√°lise individual
    if args.project:
        success = runner.run_single_analysis(args.project, args.file)
        sys.exit(0 if success else 1)
    
    # Se chegou aqui, nenhum comando foi especificado
    parser.print_help()


if __name__ == "__main__":
    main()