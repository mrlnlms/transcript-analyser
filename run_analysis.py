#!/usr/bin/env python3
"""
üéØ TRANSCRIPT ANALYZER - CLI PRINCIPAL
üîß python run_analysis.py --project grupo_docentes

Interface de linha de comando para an√°lise automatizada de entrevistas.
"""

import argparse
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Optional, List

# Importar m√≥dulos do sistema
try:
    from config_loader import ConfigLoader, ResourceManager, ProjectConfig
    from engine.analyzer_core import TranscriptAnalyzer
    from visuals.dashboard_generator import DashboardGenerator
except ImportError as e:
    print(f"‚ùå Erro ao importar m√≥dulos b√°sicos: {e}")
    print("üí° Execute primeiro: python setup.py para configurar o ambiente")
    sys.exit(1)

# Tentar importar sistema escal√°vel de visualiza√ß√µes
try:
    from visuals.visualization_manager import ScalableVisualizationManager
    SCALABLE_VISUALS = True
    print("‚úÖ Sistema escal√°vel de visualiza√ß√µes carregado")
except ImportError:
    SCALABLE_VISUALS = False
    print("‚ö†Ô∏è Sistema escal√°vel n√£o dispon√≠vel, usando sistema tradicional")


class AnalysisRunner:
    """üöÄ Orquestrador principal das an√°lises"""
    
    def __init__(self):
        self.config_loader = ConfigLoader()
        self.resource_manager = ResourceManager(self.config_loader)
        
    def run_single_analysis(self, project_name: str, file_path: Optional[str] = None):
        """üìä Executa an√°lise individual"""
        
        print(f"üéØ INICIANDO AN√ÅLISE: {project_name}")
        print("=" * 50)
        
        try:
            # 1. Carregar configura√ß√£o
            config = self.config_loader.load_project_config(project_name)
            print(f"‚úÖ Configura√ß√£o carregada: {config.project_name}")
            
            # 2. Inicializar analisador
            analyzer = TranscriptAnalyzer(config, self.resource_manager)
            
            # 3. Detectar arquivos para an√°lise
            project_dir = self.config_loader.projects_dir / project_name
            if file_path:
                files_to_analyze = [Path(file_path)]
            else:
                files_to_analyze = list((project_dir / "arquivos").glob("*.txt"))
            
            if not files_to_analyze:
                print("‚ùå Nenhum arquivo .txt encontrado em arquivos/")
                return False
            
            print(f"üìÅ Arquivos detectados: {len(files_to_analyze)}")
            
            # 4. Processar cada arquivo
            results = []
            for file_path in files_to_analyze:
                print(f"\nüîç Analisando: {file_path.name}")
                
                try:
                    result = analyzer.analyze_transcript(file_path)
                    result['filename'] = file_path.name
                    results.append(result)
                    print(f"‚úÖ {file_path.name} processado")
                    
                except Exception as e:
                    print(f"‚ùå Erro em {file_path.name}: {e}")
                    continue
            
            if not results:
                print("‚ùå Nenhuma an√°lise foi conclu√≠da com sucesso")
                return False
            
            # 5. Gerar visualiza√ß√µes
            if config.output['generate_visuals']:
                print(f"\nüìä Gerando visualiza√ß√µes...")
                
                for result in results:
                    output_dir = project_dir / "resultados" / result['filename'].replace('.txt', '')
                    output_dir.mkdir(parents=True, exist_ok=True)
                    
                    # Usar m√©todo inteligente de visualiza√ß√£o
                    self._generate_visualizations_smart(result, str(output_dir), config)
            
            # 6. Gerar relat√≥rios se habilitado
            if config.output['generate_markdown']:
                print(f"\nüìù Gerando relat√≥rios...")
                self._generate_markdown_reports(results, project_dir / "resultados")
            
            # 7. Resumo final
            self._print_analysis_summary(results, project_name)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erro cr√≠tico na an√°lise: {e}")
            return False
    
    def _generate_visualizations_smart(self, result, output_dir, config):
        """üé® Gera visualiza√ß√µes usando sistema escal√°vel ou fallback"""
        
        if SCALABLE_VISUALS:
            try:
                # Usar sistema novo e escal√°vel
                viz_manager = ScalableVisualizationManager(config.output)
                
                print(f"üé® Backends dispon√≠veis: {viz_manager.get_available_backends()}")
                
                # Gr√°fico de m√©tricas
                metrics_data = {
                    'categories': ['Sentimento', 'Coer√™ncia', 'Abertura'],
                    'values': [
                        result['global_metrics']['global_sentiment'],
                        result['global_metrics']['thematic_coherence'], 
                        result['global_metrics']['emotional_openness']
                    ]
                }
                
                metrics_config = {
                    'title': f'M√©tricas Globais - {result["filename"]}',
                    'output_path': str(Path(output_dir) / 'metricas_globais.png'),
                    'figsize': (12, 8),
                    'bar_params': {'alpha': 0.8, 'color': ['skyblue', 'lightgreen', 'coral']}
                }
                
                viz_manager.create_visualization('bar_chart', metrics_data, metrics_config)
                
                # Timeline emocional se houver dados temporais
                if result.get('temporal_analysis'):
                    timeline_data = {
                        'x': [i for i in range(len(result['temporal_analysis']))],
                        'y': [seg['sentiment'] for seg in result['temporal_analysis']]
                    }
                    
                    timeline_config = {
                        'title': 'Timeline Emocional',
                        'xlabel': 'Segmentos',
                        'ylabel': 'Sentimento',
                        'output_path': str(Path(output_dir) / 'timeline_emocional.html'),
                        'trace_name': 'Evolu√ß√£o Emocional'
                    }
                    
                    viz_manager.create_visualization('line_plot', timeline_data, timeline_config, backend='plotly')
                
                # Rede de conceitos se dispon√≠vel
                if result.get('concept_network'):
                    network_data = {
                        'nodes': [conn['word1'] for conn in result['concept_network'][:10]] + 
                                [conn['word2'] for conn in result['concept_network'][:10]],
                        'edges': [(conn['word1'], conn['word2']) for conn in result['concept_network'][:10]]
                    }
                    
                    network_config = {
                        'title': 'Rede de Conceitos',
                        'output_path': str(Path(output_dir) / 'rede_conceitos.html'),
                        'node_params': {'node_size': 300, 'node_color': 'lightblue'},
                        'edge_params': {'width': 2, 'alpha': 0.7}
                    }
                    
                    viz_manager.create_visualization('network_graph', network_data, network_config, backend='plotly')
                
                print("‚úÖ Visualiza√ß√µes escal√°veis geradas")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro no sistema escal√°vel: {e}")
                print("üîÑ Usando sistema tradicional como fallback...")
                self._generate_visualizations_traditional(result, output_dir, config)
        else:
            # Usar sistema tradicional
            self._generate_visualizations_traditional(result, output_dir, config)
    
    def _generate_visualizations_traditional(self, result, output_dir, config):
        """üìä Gera visualiza√ß√µes usando sistema tradicional"""
        try:
            dashboard = DashboardGenerator(config)
            dashboard.generate_complete_dashboard(result, output_dir)
            print("‚úÖ Visualiza√ß√µes tradicionais geradas")
        except Exception as e:
            print(f"‚ùå Erro ao gerar visualiza√ß√µes tradicionais: {e}")
    
    def run_comparative_analysis(self, project_names: List[str]):
        """üîÑ Executa an√°lise comparativa entre projetos"""
        
        print(f"üîÑ AN√ÅLISE COMPARATIVA")
        print(f"üìä Projetos: {', '.join(project_names)}")
        print("=" * 50)
        
        try:
            all_results = []
            
            # Coletar resultados de todos os projetos
            for project_name in project_names:
                config = self.config_loader.load_project_config(project_name)
                analyzer = TranscriptAnalyzer(config, self.resource_manager)
                
                project_dir = self.config_loader.projects_dir / project_name
                files = list((project_dir / "arquivos").glob("*.txt"))
                
                project_results = []
                for file_path in files:
                    result = analyzer.analyze_transcript(file_path)
                    result['project'] = project_name
                    result['filename'] = file_path.name
                    project_results.append(result)
                
                all_results.extend(project_results)
                print(f"‚úÖ {project_name}: {len(project_results)} arquivos processados")
            
            # An√°lise comparativa
            from engine.comparative_analyzer import ComparativeAnalyzer
            
            comp_analyzer = ComparativeAnalyzer()
            comparison_results = comp_analyzer.compare_projects(all_results)
            
            # Gerar visualiza√ß√µes comparativas
            dashboard = DashboardGenerator(None)  # Usar config padr√£o para compara√ß√£o
            
            output_dir = Path("output") / f"comparative_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            dashboard.generate_comparative_dashboard(
                comparison_results,
                output_dir=str(output_dir)
            )
            
            print(f"\n‚úÖ An√°lise comparativa conclu√≠da")
            print(f"üìÇ Resultados salvos em: {output_dir}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise comparativa: {e}")
            return False
    
    def _generate_markdown_reports(self, results: List[dict], output_dir: Path):
        """üìù Gera relat√≥rios em Markdown"""
        
        for result in results:
            filename = result['filename'].replace('.txt', '.md')
            report_path = output_dir / filename
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(self._create_markdown_content(result))
            
            print(f"üìÑ Relat√≥rio gerado: {filename}")
    
    def _create_markdown_content(self, result: dict) -> str:
        """üìã Cria conte√∫do do relat√≥rio em Markdown"""
        
        content = f"""# An√°lise de Entrevista: {result['filename']}

**Data da An√°lise:** {datetime.now().strftime('%d/%m/%Y %H:%M')}

## üìä M√©tricas Globais

- **Sentimento Global:** {result['global_metrics']['global_sentiment']:.2f}
- **Coer√™ncia Tem√°tica:** {result['global_metrics']['thematic_coherence']:.2f}
- **Abertura Emocional:** {result['global_metrics']['emotional_openness']:.2f}

## üé≠ An√°lise Lingu√≠stica

- **Total de Hesita√ß√µes:** {result['linguistic_patterns']['total_hesitations']}
- **Raz√£o Incerteza/Certeza:** {result['linguistic_patterns']['uncertainty_count']}/{result['linguistic_patterns']['certainty_count']}
- **Complexidade M√©dia:** {result['linguistic_patterns']['avg_sentence_length']:.1f} palavras/frase

## üìà T√≥picos Principais

"""
        
        # Adicionar t√≥picos
        for i, topic in enumerate(result['topics'][:5]):
            distribution = result['topic_distribution'][i]
            content += f"### T√≥pico {i+1} ({distribution:.1%})\n"
            content += f"**Palavras-chave:** {', '.join(topic['words'][:8])}\n\n"
        
        # Adicionar contradi√ß√µes se existirem
        if result.get('contradictions'):
            content += "## ‚ö†Ô∏è Contradi√ß√µes Detectadas\n\n"
            for i, contradiction in enumerate(result['contradictions'][:3]):
                content += f"### Contradi√ß√£o {i+1}\n"
                content += f"- **T√≥pico:** {', '.join(contradiction['topic_words'][:5])}\n"
                content += f"- **Intensidade:** {contradiction['intensity']:.2f}\n\n"
        
        return content
    
    def _print_analysis_summary(self, results: List[dict], project_name: str):
        """üìã Imprime resumo da an√°lise"""
        
        print(f"\nüéØ RESUMO DA AN√ÅLISE: {project_name}")
        print("=" * 50)
        
        print(f"üìÅ Arquivos processados: {len(results)}")
        
        # M√©tricas m√©dias
        avg_sentiment = sum(r['global_metrics']['global_sentiment'] for r in results) / len(results)
        avg_coherence = sum(r['global_metrics']['thematic_coherence'] for r in results) / len(results)
        avg_openness = sum(r['global_metrics']['emotional_openness'] for r in results) / len(results)
        
        print(f"üòä Sentimento m√©dio: {avg_sentiment:+.2f}")
        print(f"üéØ Coer√™ncia m√©dia: {avg_coherence:.2f}")
        print(f"üí≠ Abertura m√©dia: {avg_openness:.2f}")
        
        # Arquivos com problemas
        problematic = [r for r in results if r['global_metrics']['thematic_coherence'] < 0.3]
        if problematic:
            print(f"\n‚ö†Ô∏è Arquivos com baixa coer√™ncia: {len(problematic)}")
            for r in problematic:
                print(f"   - {r['filename']}")
        
        print(f"\n‚úÖ An√°lise conclu√≠da com sucesso!")


def test_visualization_system():
    """üß™ Testa o sistema de visualiza√ß√µes"""
    
    print("üß™ TESTANDO SISTEMA DE VISUALIZA√á√ïES")
    print("=" * 50)
    
    if not SCALABLE_VISUALS:
        print("‚ùå Sistema escal√°vel n√£o dispon√≠vel para teste")
        return
    
    try:
        from visuals.visualization_manager import ScalableVisualizationManager
        
        # Criar gerenciador
        viz_manager = ScalableVisualizationManager()
        
        print(f"üé® Backends dispon√≠veis: {viz_manager.get_available_backends()}")
        
        # Dados de teste
        test_data = {
            'categories': ['A', 'B', 'C', 'D'],
            'values': [10, 25, 15, 30]
        }
        
        test_config = {
            'title': 'Teste de Gr√°fico de Barras',
            'output_path': 'test_bar_chart.png',
            'xlabel': 'Categorias',
            'ylabel': 'Valores'
        }
        
        # Testar cada backend
        for backend in viz_manager.get_available_backends():
            print(f"\nüîß Testando backend: {backend}")
            
            test_config['output_path'] = f'test_bar_chart_{backend}.png'
            if backend == 'plotly':
                test_config['output_path'] = f'test_bar_chart_{backend}.html'
            
            result = viz_manager.create_visualization('bar_chart', test_data, test_config, backend)
            
            if result:
                print(f"‚úÖ Sucesso: {result}")
            else:
                print(f"‚ùå Falha no backend {backend}")
        
        print("\n‚úÖ Teste conclu√≠do!")
        
    except Exception as e:
        print(f"‚ùå Erro no teste: {e}")


def main():
    """üéØ Fun√ß√£o principal do CLI"""
    
    parser = argparse.ArgumentParser(
        description="üéØ Transcript Analyzer - An√°lise automatizada de entrevistas qualitativas",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python run_analysis.py --project grupo_docentes
  python run_analysis.py --project professores_2024 --file entrevista1.txt
  python run_analysis.py --compare projeto1 projeto2 projeto3
  python run_analysis.py --test-visuals
        """
    )
    
    parser.add_argument(
        '--project', '-p',
        help="Nome do projeto para an√°lise"
    )
    
    parser.add_argument(
        '--file', '-f',
        help="Arquivo espec√≠fico para analisar (opcional)"
    )
    
    parser.add_argument(
        '--compare', '-c',
        nargs='+',
        help="Executar an√°lise comparativa entre projetos"
    )
    
    parser.add_argument(
        '--create-project',
        help="Criar novo projeto com estrutura padr√£o"
    )
    
    parser.add_argument(
        '--list-projects', '-l',
        action='store_true',
        help="Listar projetos dispon√≠veis"
    )
    
    parser.add_argument(
        '--setup',
        action='store_true',
        help="Configurar ambiente inicial"
    )
    
    parser.add_argument(
        '--test-visuals',
        action='store_true',
        help="Testar sistema de visualiza√ß√µes"
    )
    
    args = parser.parse_args()
    
    # Configurar ambiente se solicitado
    if args.setup:
        from config_loader import setup_environment
        setup_environment()
        return
    
    # Testar visualiza√ß√µes
    if args.test_visuals:
        test_visualization_system()
        return
    
    runner = AnalysisRunner()
    
    # Criar projeto
    if args.create_project:
        runner.config_loader.create_default_project(args.create_project)
        print(f"‚úÖ Projeto '{args.create_project}' criado")
        print(f"üìÅ Adicione arquivos .txt em: projects/{args.create_project}/arquivos/")
        return
    
    # Listar projetos
    if args.list_projects:
        projects_dir = runner.config_loader.projects_dir
        projects = [d.name for d in projects_dir.iterdir() if d.is_dir()]
        
        if projects:
            print("üìÅ Projetos dispon√≠veis:")
            for project in projects:
                config_file = projects_dir / project / "config_analise.json"
                status = "‚úÖ" if config_file.exists() else "‚ùå"
                print(f"   {status} {project}")
        else:
            print("‚ùå Nenhum projeto encontrado")
            print("üí° Use: --create-project nome_projeto")
        return
    
    # An√°lise comparativa
    if args.compare:
        success = runner.run_comparative_analysis(args.compare)
        sys.exit(0 if success else 1)
    
    # An√°lise individual
    if args.project:
        success = runner.run_single_analysis(args.project, args.file)
        sys.exit(0 if success else 1)
    
    # Se chegou aqui, nenhum comando foi especificado
    parser.print_help()


if __name__ == "__main__":
    main()