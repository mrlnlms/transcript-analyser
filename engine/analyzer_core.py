"""ðŸ” Engine de anÃ¡lise principal"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional


class TranscriptAnalyzer:
    """Analisador principal de transcriÃ§Ãµes"""
    
    def __init__(self, config, resource_manager):
        self.config = config
        self.resources = resource_manager
        print(f"âœ… TranscriptAnalyzer inicializado para projeto: {config.project_name}")
    
    def analyze_transcript(self, file_path: Path) -> Dict[str, Any]:
        """AnÃ¡lise completa de uma transcriÃ§Ã£o"""
        
        print(f"ðŸ” Iniciando anÃ¡lise de: {file_path.name}")
        
        try:
            # Ler arquivo
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            if not text.strip():
                raise ValueError("Arquivo vazio ou invÃ¡lido")
            
            # TEMPORÃRIO: Usar dados mockados
            #from tests.mock_data import load_mock_result
            #result = load_mock_result(file_path.name)
            
            # TODO: Implementar anÃ¡lise real
            # ANÃLISE REAL (bÃ¡sica por enquanto)
            result = {
                'filename': file_path.name,
                'status': 'success',
                'global_metrics': {
                    'global_sentiment': 0.0,  # TODO: implementar
                    'thematic_coherence': 0.5,
                    'emotional_openness': 1.0,
                    'sentiment_variance': 0.2,
                    'total_hesitations': 0
                },
                'word_frequencies': self._count_word_frequencies(text),
                'temporal_analysis': [],  # TODO: implementar
                'phases': {},  # TODO: implementar
                'linguistic_patterns': {},  # TODO: implementar
                'topics': [],  # TODO: implementar
                'topic_distribution': [],
                'topic_hierarchy': {'nodes': [], 'edges': []},
                'contradictions': [],
                'concept_network': []
            }

            print(f"âœ… AnÃ¡lise concluÃ­da: {file_path.name}")
            return result
            
        except Exception as e:
            print(f"âŒ Erro na anÃ¡lise de {file_path.name}: {e}")
            raise

    def _count_word_frequencies(self, text: str) -> Dict[str, int]:
        """Conta frequÃªncia real das palavras"""
        from collections import Counter
        import re
        
        # Limpar e tokenizar
        text_lower = text.lower()
        # Remove pontuaÃ§Ã£o e separa palavras
        words = re.findall(r'\b[a-zÃ¡Ã Ã¢Ã£Ã©Ã¨ÃªÃ­Ã¯Ã³Ã´ÃµÃ¶ÃºÃ§Ã±]+\b', text_lower)
        
        # Filtrar stopwords se disponÃ­vel
        stopwords = set()
        if hasattr(self, 'resource_manager'):
            stopwords = set(self.resource_manager.get_stopwords())
        
        # Contar palavras significativas
        filtered_words = [w for w in words if len(w) > 3 and w not in stopwords]
        word_counts = Counter(filtered_words)
        
        # Retornar top 50 palavras
        return dict(word_counts.most_common(50))