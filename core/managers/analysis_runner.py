#!/usr/bin/env python3
"""
Analysis Runner - CoordenaÃ§Ã£o de anÃ¡lises
"""

import logging
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

# Imports dos orquestradores
from core.engine.analysis_orchestrator import AnalysisOrchestrator
from core.visuals.chart_orchestrator import ChartOrchestrator
from core.generators.markdown_generator import MarkdownReportGenerator


class AnalysisRunner:
    """Coordena a execuÃ§Ã£o de anÃ¡lises"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.analysis_orchestrator = AnalysisOrchestrator()
        self.chart_orchestrator = ChartOrchestrator()
        self.markdown_generator = MarkdownReportGenerator()
        
    def analyze_project(self, project_path: Path) -> bool:
        """Executa anÃ¡lise completa de um projeto"""
        try:
            print(f"\nğŸ¯ INICIANDO ANÃLISE: {project_path.name}")
            print("=" * 50)
            
            # Encontrar arquivos
            arquivos_dir = project_path / "arquivos"
            txt_files = list(arquivos_dir.glob("*.txt"))
            
            if not txt_files:
                print("âŒ Nenhum arquivo .txt encontrado!")
                return False
                
            print(f"ğŸ“ Arquivos detectados: {len(txt_files)}")
            
            results = []
            
            # Analisar cada arquivo
            for file_path in txt_files:
                print(f"\nğŸ” Analisando: {file_path.name}")
                
                # AnÃ¡lise via orchestrator
                result = self.analysis_orchestrator.analyze_transcript(file_path)
                
                if result:
                    results.append(result)
                    print(f"âœ… {file_path.name} processado")
                else:
                    print(f"âŒ Erro ao processar {file_path.name}")
            
            if not results:
                print("\nâŒ Nenhum arquivo foi processado com sucesso!")
                return False
            
            # Gerar visualizaÃ§Ãµes e relatÃ³rios
            output_dir = project_path / "output"
            output_dir.mkdir(exist_ok=True)
            
            print("\nğŸ“Š Gerando visualizaÃ§Ãµes...")
            for result in results:
                # GrÃ¡ficos via orchestrator
                self.chart_orchestrator.analyze(result, str(output_dir))
                
                # RelatÃ³rio markdown
                self.markdown_generator.generate_report(result, output_dir)
            
            # Resumo final
            self._print_summary(results)
            
            print(f"\nâœ… AnÃ¡lise concluÃ­da com sucesso!")
            return True
            
        except Exception as e:
            self.logger.error(f"Erro na anÃ¡lise: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _print_summary(self, results: List[Dict]):
        """Imprime resumo da anÃ¡lise"""
        print(f"\nğŸ¯ RESUMO DA ANÃLISE")
        print("=" * 50)
        print(f"ğŸ“ Arquivos processados: {len(results)}")
        
        # Calcular mÃ©dias
        sentiments = []
        coherences = []
        
        for result in results:
            if 'global_metrics' in result:
                metrics = result['global_metrics']
                sentiments.append(metrics.get('global_sentiment', 0))
                coherences.append(metrics.get('thematic_coherence', 0))
        
        if sentiments:
            avg_sentiment = sum(sentiments) / len(sentiments)
            print(f"ğŸ˜Š Sentimento mÃ©dio: {avg_sentiment:.2f}")
            
        if coherences:
            avg_coherence = sum(coherences) / len(coherences)
            print(f"ğŸ¯ CoerÃªncia mÃ©dia: {avg_coherence:.2f}")


# Teste bÃ¡sico
if __name__ == "__main__":
    print("âœ… Analysis Runner criado!")
    # NÃ£o podemos testar completamente sem os imports
