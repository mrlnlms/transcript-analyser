#!/usr/bin/env python3
"""
Markdown Report Generator
Gera relatÃ³rios em Markdown a partir dos resultados de anÃ¡lise
"""

import logging
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

logger = logging.getLogger(__name__)


class MarkdownReportGenerator:
    """Gerador de relatÃ³rios em Markdown com interpretaÃ§Ãµes automÃ¡ticas"""
    
    def __init__(self):
        self.logger = logger
        
    def generate_report(self, result: Dict[str, Any], output_path: Path) -> str:
        """
        Gera relatÃ³rio completo em Markdown
        
        Args:
            result: Resultados da anÃ¡lise
            output_path: Caminho para salvar o relatÃ³rio
            
        Returns:
            Caminho do arquivo gerado
        """
        try:
            self.logger.info("ï¿½ï¿½ Gerando relatÃ³rio Markdown...")
            
            # Criar conteÃºdo
            content = self._create_content(result)
            
            # Salvar arquivo
            # Salvar arquivo com nome do arquivo original
            filename_base = result.get('filename', 'arquivo').replace('.txt', '')
            report_path = output_path / f'report_{filename_base}.md'
            report_path.write_text(content, encoding='utf-8')
            
            self.logger.info(f"âœ… RelatÃ³rio salvo em: {report_path}")
            return str(report_path)
            
        except Exception as e:
            self.logger.error(f"âŒ Erro ao gerar relatÃ³rio: {e}")
            import traceback
            traceback.print_exc()
            return ""
    
    def _create_content(self, result: Dict[str, Any]) -> str:
        """Cria conteÃºdo completo do relatÃ³rio"""
        sections = []
        
        # CabeÃ§alho
        sections.append(self._create_header(result))
        
        # Resumo executivo
        sections.append(self._create_executive_summary(result))
        
        # MÃ©tricas globais
        if 'global_metrics' in result:
            sections.append(self._create_global_metrics_section(result['global_metrics']))
        
        # AnÃ¡lise temporal
        if 'temporal_analysis' in result:
            sections.append(self._create_temporal_section(result['temporal_analysis']))
        
        # TÃ³picos
        if 'topics' in result:
            sections.append(self._create_topics_section(result))
        
        # Rede conceitual
        if 'concept_network' in result:
            sections.append(self._create_network_section(result['concept_network']))
        
        # PadrÃµes linguÃ­sticos
        if 'linguistic_patterns' in result:
            sections.append(self._create_patterns_section(result['linguistic_patterns']))
        
        # ContradiÃ§Ãµes
        if 'contradictions' in result:
            sections.append(self._create_contradictions_section(result['contradictions']))
        
        # Palavras frequentes
        if 'word_frequencies' in result:
            sections.append(self._create_frequency_section(result['word_frequencies']))
        
        # RodapÃ©
        sections.append(self._create_footer())
        
        return '\n\n'.join(filter(None, sections))
    
    def _create_header(self, result: Dict[str, Any]) -> str:
        """Cria cabeÃ§alho do relatÃ³rio"""
        filename = result.get('filename', 'arquivo')
        return f"""# ðŸ“Š RelatÃ³rio de AnÃ¡lise - {filename}

**Data**: {datetime.now().strftime('%d/%m/%Y %H:%M')}  
**Arquivo**: {filename}
"""
    
    def _create_executive_summary(self, result: Dict[str, Any]) -> str:
        """Cria resumo executivo com interpretaÃ§Ãµes principais"""
        summary_parts = ["## ðŸ“‹ Resumo Executivo\n"]
        
        # Sentimento dominante
        if 'global_metrics' in result:
            sentiment = result['global_metrics'].get('global_sentiment', 0)
            if sentiment > 0.1:
                summary_parts.append("âœ… **Sentimento geral positivo** - A transcriÃ§Ã£o apresenta tom otimista")
            elif sentiment < -0.1:
                summary_parts.append("âš ï¸ **Sentimento geral negativo** - Tons de preocupaÃ§Ã£o ou crÃ­tica detectados")
            else:
                summary_parts.append("ðŸ”µ **Sentimento neutro** - Discurso equilibrado e objetivo")
        
        # TÃ³picos principais
        if 'topics' in result and result['topics']:
            top_topic = result['topics'][0]
            summary_parts.append(f"ðŸŽ¯ **TÃ³pico principal**: {top_topic.get('label', 'N/A')}")
        
        # PadrÃµes notÃ¡veis
        if 'linguistic_patterns' in result:
            patterns = result['linguistic_patterns']
            hesitations = patterns.get('total_hesitations', 0)
            if hesitations > 5:
                summary_parts.append("ðŸ’­ **Alta hesitaÃ§Ã£o detectada** - PossÃ­vel incerteza ou reflexÃ£o profunda")
        
        return '\n'.join(summary_parts)
    
    def _create_global_metrics_section(self, metrics: Dict[str, Any]) -> str:
        """SeÃ§Ã£o de mÃ©tricas globais"""
        return f"""## ðŸ“Š MÃ©tricas Globais

- **Sentimento Global**: {metrics.get('global_sentiment', 0):.3f} {self._interpret_sentiment(metrics.get('global_sentiment', 0))}
- **CoerÃªncia TemÃ¡tica**: {metrics.get('thematic_coherence', 0):.2f} {self._interpret_coherence(metrics.get('thematic_coherence', 0))}
- **Abertura Emocional**: {metrics.get('emotional_openness', 0):.2f} {self._interpret_openness(metrics.get('emotional_openness', 0))}
"""
    
    def _create_temporal_section(self, temporal: List[Dict]) -> str:
        """SeÃ§Ã£o de anÃ¡lise temporal"""
        if not temporal:
            return ""
            
        content = ["## ðŸ“ˆ AnÃ¡lise Temporal\n"]
        
        # EstatÃ­sticas gerais
        sentiments = [seg.get('sentiment', 0) for seg in temporal]
        avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0
        
        content.append(f"**Sentimento mÃ©dio ao longo do tempo**: {avg_sentiment:.3f}")
        content.append(f"**Total de segmentos analisados**: {len(temporal)}")
        
        # Encontrar picos e vales
        if len(sentiments) > 2:
            max_idx = sentiments.index(max(sentiments))
            min_idx = sentiments.index(min(sentiments))
            content.append(f"\nðŸ”º **Pico emocional**: Segmento {max_idx + 1} (sentimento: {sentiments[max_idx]:.3f})")
            content.append(f"ðŸ”» **Vale emocional**: Segmento {min_idx + 1} (sentimento: {sentiments[min_idx]:.3f})")
        
        return '\n'.join(content)
    
    def _create_topics_section(self, result: Dict[str, Any]) -> str:
        """SeÃ§Ã£o de tÃ³picos"""
        topics = result.get('topics', [])
        distribution = result.get('topic_distribution', [])
        
        if not topics:
            return ""
            
        content = ["## ðŸŽ¯ TÃ³picos Identificados\n"]
        
        for i, topic in enumerate(topics[:5]):  # Top 5 tÃ³picos
            label = topic.get('label', f'TÃ³pico {i+1}')
            words = ', '.join(topic.get('words', [])[:5])
            
            if i < len(distribution):
                percentage = distribution[i] * 100
                content.append(f"### {label} ({percentage:.1f}%)")
            else:
                content.append(f"### {label}")
                
            content.append(f"**Palavras-chave**: {words}\n")
        
        return '\n'.join(content)
    
    def _create_network_section(self, network: List[Dict]) -> str:
        """SeÃ§Ã£o de rede conceitual"""
        if not network:
            return ""
            
        content = ["## ðŸ•¸ï¸ Rede de Conceitos\n"]
        
        # Ordenar por peso (corrigindo o erro de comparaÃ§Ã£o de dicts)
        try:
            # Filtrar apenas dicts vÃ¡lidos com 'weight'
            valid_connections = [conn for conn in network if isinstance(conn, dict) and 'weight' in conn]
            
            if valid_connections:
                # Ordenar por peso
                sorted_network = sorted(valid_connections, key=lambda x: x.get('weight', 0), reverse=True)
                
                content.append("**ConexÃµes mais fortes**:")
                for conn in sorted_network[:10]:  # Top 10 conexÃµes
                    word1 = conn.get('word1', 'N/A')
                    word2 = conn.get('word2', 'N/A')
                    weight = conn.get('weight', 0)
                    content.append(f"- {word1} â†”ï¸ {word2} (forÃ§a: {weight})")
            else:
                content.append("*Nenhuma conexÃ£o vÃ¡lida encontrada*")
                
        except Exception as e:
            self.logger.warning(f"Erro ao processar rede: {e}")
            content.append("*Erro ao processar conexÃµes da rede*")
        
        return '\n'.join(content)
    
    def _create_patterns_section(self, patterns: Dict[str, Any]) -> str:
        """SeÃ§Ã£o de padrÃµes linguÃ­sticos"""
        content = ["## ðŸ’¬ PadrÃµes LinguÃ­sticos\n"]
        
        # HesitaÃ§Ãµes
        hesitations = patterns.get('hesitation_phrases', {})
        total_hesitations = patterns.get('total_hesitations', 0)
        
        if total_hesitations > 0:
            content.append(f"**Total de hesitaÃ§Ãµes**: {total_hesitations}")
            if isinstance(hesitations, dict) and hesitations:
                content.append("**Tipos de hesitaÃ§Ã£o**:")
                for phrase, count in list(hesitations.items())[:5]:
                    content.append(f"- '{phrase}': {count} vezes")
        
        # Certeza vs Incerteza
        uncertainty = patterns.get('uncertainty_markers', {}).get('count', 0)
        certainty = patterns.get('certainty_markers', {}).get('count', 0)
        
        if uncertainty + certainty > 0:
            certainty_ratio = certainty / (certainty + uncertainty) * 100
            content.append(f"\n**Ãndice de certeza**: {certainty_ratio:.1f}%")
        
        # Comprimento mÃ©dio
        avg_length = patterns.get('avg_sentence_length', 0)
        if avg_length > 0:
            content.append(f"**Comprimento mÃ©dio das sentenÃ§as**: {avg_length:.1f} palavras")
        
        return '\n'.join(content)
    
    def _create_contradictions_section(self, contradictions: List[Dict]) -> str:
        """SeÃ§Ã£o de contradiÃ§Ãµes"""
        if not contradictions:
            return ""
            
        content = ["## âš¡ ContradiÃ§Ãµes Detectadas\n"]
        
        # Filtrar e ordenar contradiÃ§Ãµes vÃ¡lidas
        valid_contradictions = [c for c in contradictions if isinstance(c, dict) and 'score' in c]
        
        if valid_contradictions:
            sorted_contradictions = sorted(valid_contradictions, key=lambda x: x.get('score', 0), reverse=True)
            
            for i, contradiction in enumerate(sorted_contradictions[:5], 1):
                score = contradiction.get('score', 0)
                text1 = contradiction.get('text1', 'N/A')
                text2 = contradiction.get('text2', 'N/A')
                
                content.append(f"### ContradiÃ§Ã£o {i} (confianÃ§a: {score:.2f})")
                content.append(f"- **AfirmaÃ§Ã£o 1**: \"{text1}\"")
                content.append(f"- **AfirmaÃ§Ã£o 2**: \"{text2}\"\n")
        else:
            content.append("*Nenhuma contradiÃ§Ã£o significativa detectada*")
        
        return '\n'.join(content)
    
    def _create_frequency_section(self, frequencies: Dict[str, int]) -> str:
        """SeÃ§Ã£o de palavras frequentes"""
        if not frequencies:
            return ""
            
        content = ["## ðŸ“ Palavras Mais Frequentes\n"]
        
        # Ordenar por frequÃªncia
        sorted_words = sorted(frequencies.items(), key=lambda x: x[1], reverse=True)
        
        for word, count in sorted_words[:15]:  # Top 15
            content.append(f"- **{word}**: {count} ocorrÃªncias")
        
        return '\n'.join(content)
    
    def _create_footer(self) -> str:
        """RodapÃ© do relatÃ³rio"""
        return """---

ðŸ“Š *RelatÃ³rio gerado automaticamente pelo Transcript Analyzer V2.0*  
ðŸ” *Para anÃ¡lises mais detalhadas, consulte as visualizaÃ§Ãµes interativas*"""
    
    # MÃ©todos auxiliares de interpretaÃ§Ã£o
    def _interpret_sentiment(self, value: float) -> str:
        """Interpreta valor de sentimento"""
        if value > 0.3:
            return "ðŸ˜Š Muito positivo"
        elif value > 0.1:
            return "ðŸ™‚ Positivo"
        elif value > -0.1:
            return "ðŸ˜ Neutro"
        elif value > -0.3:
            return "ðŸ˜• Negativo"
        else:
            return "ðŸ˜” Muito negativo"
    
    def _interpret_coherence(self, value: float) -> str:
        """Interpreta coerÃªncia temÃ¡tica"""
        if value > 0.8:
            return "ðŸŽ¯ Excelente foco"
        elif value > 0.6:
            return "âœ… Boa estrutura"
        elif value > 0.4:
            return "ðŸ“Š Estrutura razoÃ¡vel"
        else:
            return "âš ï¸ Disperso"
    
    def _interpret_openness(self, value: float) -> str:
        """Interpreta abertura emocional"""
        if value > 2:
            return "ðŸ’– Muito expressivo"
        elif value > 1:
            return "ðŸ’¬ Expressivo"
        elif value > 0.5:
            return "ðŸ”µ Moderado"
        else:
            return "ðŸ”’ Reservado"
