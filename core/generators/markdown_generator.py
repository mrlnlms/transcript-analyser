#!/usr/bin/env python3
"""
Markdown Report Generator
Gera relat√≥rios em Markdown a partir dos resultados de an√°lise
"""

import logging
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

logger = logging.getLogger(__name__)


class MarkdownReportGenerator:
    """Gerador de relat√≥rios em Markdown com interpreta√ß√µes autom√°ticas"""
    
    def __init__(self):
        self.logger = logger
        
    def generate_report(self, result: Dict[str, Any], output_path: Path) -> str:
        """
        Gera relat√≥rio completo em Markdown
        
        Args:
            result: Resultados da an√°lise
            output_path: Caminho para salvar o relat√≥rio
            
        Returns:
            Caminho do arquivo gerado
        """
        try:
            self.logger.info("ÔøΩÔøΩ Gerando relat√≥rio Markdown...")
            
            # Criar conte√∫do
            content = self._create_content(result)
            
            # Salvar arquivo
            # Salvar arquivo com nome do arquivo original
            filename_base = result.get('filename', 'arquivo').replace('.txt', '')
            report_path = output_path / f'report_{filename_base}.md'
            report_path.write_text(content, encoding='utf-8')
            
            self.logger.info(f"‚úÖ Relat√≥rio salvo em: {report_path}")
            return str(report_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao gerar relat√≥rio: {e}")
            import traceback
            traceback.print_exc()
            return ""
    
    def _create_content(self, result: Dict[str, Any]) -> str:
        """Cria conte√∫do completo do relat√≥rio"""
        sections = []
        
        # Cabe√ßalho
        sections.append(self._create_header(result))
        
        # Resumo executivo
        sections.append(self._create_executive_summary(result))
        
        # M√©tricas globais
        if 'global_metrics' in result:
            sections.append(self._create_global_metrics_section(result['global_metrics']))
        
        # An√°lise temporal
        if 'temporal_analysis' in result:
            sections.append(self._create_temporal_section(result['temporal_analysis']))
        
        # T√≥picos
        if 'topics' in result:
            sections.append(self._create_topics_section(result))
        
        # Rede conceitual
        if 'concept_network' in result:
            sections.append(self._create_network_section(result['concept_network']))
        
        # Padr√µes lingu√≠sticos
        if 'linguistic_patterns' in result:
            sections.append(self._create_patterns_section(result['linguistic_patterns']))
        
        # Contradi√ß√µes
        if 'contradictions' in result:
            sections.append(self._create_contradictions_section(result['contradictions']))
        
        # Palavras frequentes
        if 'word_frequencies' in result:
            sections.append(self._create_frequency_section(result['word_frequencies']))
        
        # Rodap√©
        sections.append(self._create_footer())
        
        return '\n\n'.join(filter(None, sections))
    
    def _create_header(self, result: Dict[str, Any]) -> str:
        """Cria cabe√ßalho do relat√≥rio"""
        filename = result.get('filename', 'arquivo')
        return f"""# üìä Relat√≥rio de An√°lise - {filename}

**Data**: {datetime.now().strftime('%d/%m/%Y %H:%M')}  
**Arquivo**: {filename}
"""
    
    def _create_executive_summary(self, result: Dict[str, Any]) -> str:
        """Cria resumo executivo com interpreta√ß√µes principais"""
        summary_parts = ["## üìã Resumo Executivo\n"]
        
        # Sentimento dominante
        if 'global_metrics' in result:
            sentiment = result['global_metrics'].get('global_sentiment', 0)
            if sentiment > 0.1:
                summary_parts.append("‚úÖ **Sentimento geral positivo** - A transcri√ß√£o apresenta tom otimista")
            elif sentiment < -0.1:
                summary_parts.append("‚ö†Ô∏è **Sentimento geral negativo** - Tons de preocupa√ß√£o ou cr√≠tica detectados")
            else:
                summary_parts.append("üîµ **Sentimento neutro** - Discurso equilibrado e objetivo")
        
        # T√≥picos principais
        if 'topics' in result and result['topics']:
            top_topic = result['topics'][0]
            summary_parts.append(f"üéØ **T√≥pico principal**: {top_topic.get('label', 'N/A')}")
        
        # Padr√µes not√°veis
        if 'linguistic_patterns' in result:
            patterns = result['linguistic_patterns']
            hesitations = patterns.get('total_hesitations', 0)
            if hesitations > 5:
                summary_parts.append("üí≠ **Alta hesita√ß√£o detectada** - Poss√≠vel incerteza ou reflex√£o profunda")
        
        return '\n'.join(summary_parts)
    
    def _create_global_metrics_section(self, metrics: Dict[str, Any]) -> str:
        """Se√ß√£o de m√©tricas globais"""
        return f"""## üìä M√©tricas Globais

- **Sentimento Global**: {metrics.get('global_sentiment', 0):.3f} {self._interpret_sentiment(metrics.get('global_sentiment', 0))}
- **Coer√™ncia Tem√°tica**: {metrics.get('thematic_coherence', 0):.2f} {self._interpret_coherence(metrics.get('thematic_coherence', 0))}
- **Abertura Emocional**: {metrics.get('emotional_openness', 0):.2f} {self._interpret_openness(metrics.get('emotional_openness', 0))}
"""
    
    def _create_temporal_section(self, temporal: List[Dict]) -> str:
        """Se√ß√£o de an√°lise temporal"""
        if not temporal:
            return ""
            
        content = ["## üìà An√°lise Temporal\n"]
        
        # Estat√≠sticas gerais
        sentiments = [seg.get('sentiment', 0) for seg in temporal]
        avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0
        
        content.append(f"**Sentimento m√©dio ao longo do tempo**: {avg_sentiment:.3f}")
        content.append(f"**Total de segmentos analisados**: {len(temporal)}")
        
        # Encontrar picos e vales
        if len(sentiments) > 2:
            max_idx = sentiments.index(max(sentiments))
            min_idx = sentiments.index(min(sentiments))
            content.append(f"\nüî∫ **Pico emocional**: Segmento {max_idx + 1} (sentimento: {sentiments[max_idx]:.3f})")
            content.append(f"üîª **Vale emocional**: Segmento {min_idx + 1} (sentimento: {sentiments[min_idx]:.3f})")
        
        return '\n'.join(content)
    
    def _create_topics_section(self, result: Dict[str, Any]) -> str:
        """Se√ß√£o de t√≥picos"""
        topics = result.get('topics', [])
        distribution = result.get('topic_distribution', [])
        
        if not topics:
            return ""
            
        content = ["## üéØ T√≥picos Identificados\n"]
        
        for i, topic in enumerate(topics[:5]):  # Top 5 t√≥picos
            label = topic.get('label', f'T√≥pico {i+1}')
            words = ', '.join(topic.get('words', [])[:5])
            
            if i < len(distribution):
                percentage = distribution[i] * 100
                content.append(f"### {label} ({percentage:.1f}%)")
            else:
                content.append(f"### {label}")
                
            content.append(f"**Palavras-chave**: {words}\n")
        
        return '\n'.join(content)
    
    def _create_network_section(self, network: List[Dict]) -> str:
        """Se√ß√£o de rede conceitual"""
        if not network:
            return ""
            
        content = ["## üï∏Ô∏è Rede de Conceitos\n"]
        
        # Ordenar por peso (corrigindo o erro de compara√ß√£o de dicts)
        try:
            # Filtrar apenas dicts v√°lidos com 'weight'
            valid_connections = [conn for conn in network if isinstance(conn, dict) and 'weight' in conn]
            
            if valid_connections:
                # Ordenar por peso
                sorted_network = sorted(valid_connections, key=lambda x: x.get('weight', 0), reverse=True)
                
                content.append("**Conex√µes mais fortes**:")
                for conn in sorted_network[:10]:  # Top 10 conex√µes
                    word1 = conn.get('word1', 'N/A')
                    word2 = conn.get('word2', 'N/A')
                    weight = conn.get('weight', 0)
                    content.append(f"- {word1} ‚ÜîÔ∏è {word2} (for√ßa: {weight})")
            else:
                content.append("*Nenhuma conex√£o v√°lida encontrada*")
                
        except Exception as e:
            self.logger.warning(f"Erro ao processar rede: {e}")
            content.append("*Erro ao processar conex√µes da rede*")
        
        return '\n'.join(content)
    
    def _create_patterns_section(self, patterns: Dict[str, Any]) -> str:
        """Se√ß√£o de padr√µes lingu√≠sticos"""
        content = ["## üí¨ Padr√µes Lingu√≠sticos\n"]
        
        # Hesita√ß√µes
        hesitations = patterns.get('hesitation_phrases', {})
        total_hesitations = patterns.get('total_hesitations', 0)
        
        if total_hesitations > 0:
            content.append(f"**Total de hesita√ß√µes**: {total_hesitations}")
            if isinstance(hesitations, dict) and hesitations:
                content.append("**Tipos de hesita√ß√£o**:")
                for phrase, count in list(hesitations.items())[:5]:
                    content.append(f"- '{phrase}': {count} vezes")
        
        # Certeza vs Incerteza
        uncertainty = patterns.get('uncertainty_markers', {}).get('count', 0)
        certainty = patterns.get('certainty_markers', {}).get('count', 0)
        
        if uncertainty + certainty > 0:
            certainty_ratio = certainty / (certainty + uncertainty) * 100
            content.append(f"\n**√çndice de certeza**: {certainty_ratio:.1f}%")
        
        # Comprimento m√©dio
        avg_length = patterns.get('avg_sentence_length', 0)
        if avg_length > 0:
            content.append(f"**Comprimento m√©dio das senten√ßas**: {avg_length:.1f} palavras")
        
        return '\n'.join(content)
    
    def _create_contradictions_section(self, contradictions: List[Dict]) -> str:
        """Se√ß√£o de contradi√ß√µes"""
        if not contradictions:
            return ""
            
        content = ["## ‚ö° Contradi√ß√µes Detectadas\n"]
        
        # Filtrar e ordenar contradi√ß√µes v√°lidas
        valid_contradictions = [c for c in contradictions if isinstance(c, dict) and 'score' in c]
        
        if valid_contradictions:
            sorted_contradictions = sorted(valid_contradictions, key=lambda x: x.get('score', 0), reverse=True)
            
            for i, contradiction in enumerate(sorted_contradictions[:5], 1):
                score = contradiction.get('score', 0)
                text1 = contradiction.get('text1', 'N/A')
                text2 = contradiction.get('text2', 'N/A')
                
                content.append(f"### Contradi√ß√£o {i} (confian√ßa: {score:.2f})")
                content.append(f"- **Afirma√ß√£o 1**: \"{text1}\"")
                content.append(f"- **Afirma√ß√£o 2**: \"{text2}\"\n")
        else:
            content.append("*Nenhuma contradi√ß√£o significativa detectada*")
        
        return '\n'.join(content)
    
    def _create_frequency_section(self, frequencies: Dict[str, int]) -> str:
        """Se√ß√£o de palavras frequentes"""
        if not frequencies:
            return ""
            
        content = ["## üìù Palavras Mais Frequentes\n"]
        
        # Ordenar por frequ√™ncia
        sorted_words = sorted(frequencies.items(), key=lambda x: x[1], reverse=True)
        
        for word, count in sorted_words[:15]:  # Top 15
            content.append(f"- **{word}**: {count} ocorr√™ncias")
        
        return '\n'.join(content)
    
    def _create_footer(self) -> str:
        """Rodap√© do relat√≥rio"""
        return """---

üìä *Relat√≥rio gerado automaticamente pelo Transcript Analyzer V2.0*  
üîç *Para an√°lises mais detalhadas, consulte as visualiza√ß√µes interativas*"""
    
    # M√©todos auxiliares de interpreta√ß√£o
    def _interpret_sentiment(self, value: float) -> str:
        """Interpreta valor de sentimento"""
        if value > 0.3:
            return "üòä Muito positivo"
        elif value > 0.1:
            return "üôÇ Positivo"
        elif value > -0.1:
            return "üòê Neutro"
        elif value > -0.3:
            return "üòï Negativo"
        else:
            return "üòî Muito negativo"
    
    def _interpret_coherence(self, value: float) -> str:
        """Interpreta coer√™ncia tem√°tica"""
        if value > 0.8:
            return "üéØ Excelente foco"
        elif value > 0.6:
            return "‚úÖ Boa estrutura"
        elif value > 0.4:
            return "üìä Estrutura razo√°vel"
        else:
            return "‚ö†Ô∏è Disperso"
    
    def _interpret_openness(self, value: float) -> str:
        """Interpreta abertura emocional"""
        if value > 2:
            return "üíñ Muito expressivo"
        elif value > 1:
            return "üí¨ Expressivo"
        elif value > 0.5:
            return "üîµ Moderado"
        else:
            return "üîí Reservado"
